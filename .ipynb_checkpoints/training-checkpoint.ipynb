{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186f0987-89bf-4ed9-97dc-e2f7aa8ed091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16011b70-7be3-42ec-87fd-5061d0fe971c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f1c5e0-eca9-4317-8a0d-dce3ed1fa65a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flatten, Dense, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f433b1f-a458-49ac-ad12-5cf1dac579ef",
   "metadata": {},
   "source": [
    "# Define directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0f158-51ab-41c0-9ce9-e41cf2106cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_dataset_dir = 'blood-dataset'\n",
    "train_dir = os.path.join(blood_dataset_dir, 'train')\n",
    "eval_dir = os.path.join(blood_dataset_dir, 'eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc95a7c-976e-45cc-9009-735c2f2128e3",
   "metadata": {},
   "source": [
    "# Check if TFRecord files exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b8b9d-cc77-4c15-a054-44e2afc2db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_record_file = os.path.join(train_dir, 'train.record')\n",
    "eval_record_file = os.path.join(eval_dir, 'eval.record')\n",
    "\n",
    "if not os.path.isfile(train_record_file):\n",
    "    raise FileNotFoundError(f\"Training TFRecord file not found: {train_record_file}\")\n",
    "if not os.path.isfile(eval_record_file):\n",
    "    raise FileNotFoundError(f\"Evaluation TFRecord file not found: {eval_record_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455d8c8-bd49-422c-8100-f709978c947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of classes\n",
    "num_classes = 2  # Update based on your dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78246e0a-b6b6-41cc-aa34-ab1b45023195",
   "metadata": {},
   "source": [
    "# Function to parse a single TFRecord example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f77e5-7d74-48bd-8c4e-6b34d54ab50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = parsed_example['label']\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d224f-d8f6-407f-a376-ba93528399aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and evaluation datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0f02a-f789-4b86-8ffa-e8ac853b264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and evaluation datasets\n",
    "train_dataset = (\n",
    "    tf.data.TFRecordDataset(train_record_file)\n",
    "    .map(parse_tfrecord)\n",
    "    .batch(32)\n",
    "    .shuffle(buffer_size=10000)\n",
    "    .repeat()  # Repeat the dataset indefinitely\n",
    ")\n",
    "\n",
    "eval_dataset = (\n",
    "    tf.data.TFRecordDataset(eval_record_file)\n",
    "    .map(parse_tfrecord)\n",
    "    .batch(32)\n",
    "    .repeat()  # Repeat the dataset indefinitely\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32b7a4-f921-4049-ac89-2d8e62e6843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028d952-e201-47ce-9a27-f6ebad2ff496",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers for classification\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03764c-1542-491d-927c-cd98dd01f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e41c4-3916-4ee2-91a9-e6e056945c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with metrics\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4abea3-615e-4985-a188-321ccf1b1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary to check architecture\n",
    "model.summary()\n",
    "\n",
    "# Optionally, inspect a sample from the dataset\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab7bf2-0a26-473b-b4e1-eda6364f5a8f",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35746218-a2ff-4de1-a80b-bf94e7c8fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    history = model.fit(train_dataset, epochs=5, validation_data=eval_dataset)\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffe53d-ff7d-45c6-849c-731d54bc5ec6",
   "metadata": {},
   "source": [
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc20fd3-b889-4492-8bec-7b55d403ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(os.path.join(blood_dataset_dir, 'output_model_directory', 'saved_model'))\n",
    "# Save the model\n",
    "#model.save(os.path.join(blood_dataset_dir, 'output_model_directory', 'saved_model.h5'))\n",
    "# Save the model in SavedModel format\n",
    "tf.saved_model.save(model, os.path.join(blood_dataset_dir, 'output_model_directory', 'saved_model'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
