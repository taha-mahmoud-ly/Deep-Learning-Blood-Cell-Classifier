{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32d0bfb-7fd0-46db-891f-8110d1c0d70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_check_is_pytorch_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the trained YOLOv8 model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/detect/train11/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Perform object detection on test images\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython_pg/tf_od/blood-dataset/test_images/image-1.png\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.11/site-packages/ultralytics/engine/model.py:294\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: Union[\u001b[38;5;28mstr\u001b[39m, Path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    Loads parameters from the specified weights file into the model.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m        AssertionError: If the model is not a PyTorch model.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_is_pytorch_model()\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weights, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m    296\u001b[0m         weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m attempt_load_one_weight(weights)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_check_is_pytorch_model'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO.load('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Perform object detection on test images\n",
    "for image_path in ['python_pg/tf_od/blood-dataset/test_images/image-1.png']:\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Visualize the detection results\n",
    "    results.plot()\n",
    "    \n",
    "    # Access the detection metrics\n",
    "    boxes = results.boxes\n",
    "    print(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b9e235-3eb7-4f67-a1cf-bc4d5a83e0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "YOLO.__init__() got an unexpected keyword argument 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the trained YOLOv8 model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/detect/train11/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Perform object detection on test images\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython_pg/tf_od/blood-dataset/test_images/1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: YOLO.__init__() got an unexpected keyword argument 'weights'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLOv8 model\n",
    "model = YOLO(weights='runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Perform object detection on test images\n",
    "for image_path in ['python_pg/tf_od/blood-dataset/test_images/1.jpg']:\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Visualize the detection results\n",
    "    results.plot()\n",
    "    \n",
    "    # Access the detection metrics\n",
    "    boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "    print(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd0de61-b585-4561-aa0c-9b81472bb0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 252.6ms\n",
      "Speed: 5.0ms preprocess, 252.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m model(image_path)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Alternatively, use plot() for more detailed visualization\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Access the detection metrics (optional)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m boxes \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mpandas()\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming you want to access bounding box coordinates\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "model = model.load('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Perform object detection on test images\n",
    "for image_path in ['./blood-dataset/test_images/image-1.png']:\n",
    "    results = model(image_path)\n",
    "    \n",
    "    # Visualize the detection results\n",
    "    results.show()  # Alternatively, use plot() for more detailed visualization\n",
    "    \n",
    "    # Access the detection metrics (optional)\n",
    "    boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "    print(boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653b0d2e-f0ac-4fa9-90cb-36d427b777f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 304.8ms\n",
      "Speed: 5.6ms preprocess, 304.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m model(image_path)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Ensure there are detections in the results\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpred:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Alternatively, use plot() for more detailed visualization\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Access the detection metrics (optional)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "model = model.load('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Perform object detection on test images\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "results = model(image_path)\n",
    "\n",
    "# Ensure there are detections in the results\n",
    "if results.pred:\n",
    "    # Visualize the detection results\n",
    "    results.show()  # Alternatively, use plot() for more detailed visualization\n",
    "    \n",
    "    # Access the detection metrics (optional)\n",
    "    boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "    print(boxes)\n",
    "else:\n",
    "    print(f\"No detections found in {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df558c41-a57b-4598-8b43-d3e1d8544647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 319/355 items from pretrained weights\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 256.4ms\n",
      "Speed: 6.4ms preprocess, 256.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'xyxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m model(image_path)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Check for detections (assuming results is a Results object)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results\u001b[38;5;241m.\u001b[39mxyxy) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Check if there are any detections in xyxy list\u001b[39;00m\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Alternatively, results.plot() for more detailed visualization\u001b[39;00m\n\u001b[1;32m     20\u001b[0m   \u001b[38;5;66;03m# Access the detection metrics (optional)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'xyxy'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "model = model.load('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Perform object detection on test images\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "\n",
    "# Get detection results\n",
    "results = model(image_path)\n",
    "\n",
    "# Check for detections (assuming results is a Results object)\n",
    "if len(results.xyxy) > 0:  # Check if there are any detections in xyxy list\n",
    "  # Visualize the detection results\n",
    "  results.show()  # Alternatively, results.plot() for more detailed visualization\n",
    "\n",
    "  # Access the detection metrics (optional)\n",
    "  boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "  print(boxes)\n",
    "else:\n",
    "  print(f\"No detections found in {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "372ef8af-6293-4ccb-a080-7fa153e660be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from: runs/detect/train11/weights/best.pt\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Model weights loaded successfully.\n",
      "Reading test image from: ./blood-dataset/test_images/image-1.png\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 267.8ms\n",
      "Speed: 5.0ms preprocess, 267.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Test image read successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     exit()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Ensure there are detections in the results\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpred:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing detection results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Alternatively, use plot() for more detailed visualization\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "weights_path = 'runs/detect/train11/weights/best.pt'\n",
    "print(f\"Loading model weights from: {weights_path}\")\n",
    "model = model.load(weights_path)\n",
    "print(\"Model weights loaded successfully.\")\n",
    "\n",
    "# Perform object detection on test images\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "print(f\"Reading test image from: {image_path}\")\n",
    "try:\n",
    "    results = model(image_path, conf=0.01)\n",
    "    print(\"Test image read successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading test image: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure there are detections in the results\n",
    "if results.pred:\n",
    "    # Visualize the detection results\n",
    "    print(\"Visualizing detection results...\")\n",
    "    results.show()  # Alternatively, use plot() for more detailed visualization\n",
    "    print(\"Detection results visualized.\")\n",
    "    \n",
    "    # Access the detection metrics (optional)\n",
    "    print(\"Accessing detection metrics...\")\n",
    "    boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "    print(\"Detection metrics accessed successfully.\")\n",
    "    print(boxes)\n",
    "else:\n",
    "    print(f\"No detections found in {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3eb7129-4d22-42ee-bbc8-acc8ac102fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from: runs/detect/train11/weights/best.pt\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Model weights loaded successfully.\n",
      "Reading test image from: ./blood-dataset/test_images/image-1.png\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 275.2ms\n",
      "Speed: 4.8ms preprocess, 275.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Test image read successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'pred'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     24\u001b[0m     results \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming the first element contains the detection results\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpred:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing detection results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Alternatively, use plot() for more detailed visualization\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_od/lib/python3.11/site-packages/ultralytics/utils/__init__.py:162\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'pred'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (tuple): Original image shape in (height, width) format.\n        boxes (Boxes, optional): Object containing detection bounding boxes.\n        masks (Masks, optional): Object containing detection masks.\n        probs (Probs, optional): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints, optional): Object containing detected keypoints for each object.\n        speed (dict): Dictionary of preprocess, inference, and postprocess speeds (ms/image).\n        names (dict): Dictionary of class names.\n        path (str): Path to the image file.\n\n    Methods:\n        update(boxes=None, masks=None, probs=None, obb=None): Updates object attributes with new detection results.\n        cpu(): Returns a copy of the Results object with all tensors on CPU memory.\n        numpy(): Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda(): Returns a copy of the Results object with all tensors on GPU memory.\n        to(*args, **kwargs): Returns a copy of the Results object with tensors on a specified device and dtype.\n        new(): Returns a new Results object with the same image, path, and names.\n        plot(...): Plots detection results on an input image, returning an annotated image.\n        show(): Show annotated results to screen.\n        save(filename): Save annotated results to file.\n        verbose(): Returns a log string for each task, detailing detections and classifications.\n        save_txt(txt_file, save_conf=False): Saves detection results to a text file.\n        save_crop(save_dir, file_name=Path(\"im.jpg\")): Saves cropped detection images.\n        tojson(normalize=False): Converts detection results to JSON format.\n    "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "weights_path = 'runs/detect/train11/weights/best.pt'\n",
    "print(f\"Loading model weights from: {weights_path}\")\n",
    "model = model.load(weights_path)\n",
    "print(\"Model weights loaded successfully.\")\n",
    "\n",
    "# Perform object detection on test images\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "print(f\"Reading test image from: {image_path}\")\n",
    "try:\n",
    "    results = model(image_path, conf=0.01)\n",
    "    print(\"Test image read successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading test image: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure there are detections in the results\n",
    "if isinstance(results, list):\n",
    "    results = results[0]  # Assuming the first element contains the detection results\n",
    "\n",
    "if results.pred:\n",
    "    # Visualize the detection results\n",
    "    print(\"Visualizing detection results...\")\n",
    "    results.show()  # Alternatively, use plot() for more detailed visualization\n",
    "    print(\"Detection results visualized.\")\n",
    "    \n",
    "    # Access the detection metrics (optional)\n",
    "    print(\"Accessing detection metrics...\")\n",
    "    boxes = results.pandas().xyxy[0]  # Assuming you want to access bounding box coordinates\n",
    "    print(\"Detection metrics accessed successfully.\")\n",
    "    print(boxes)\n",
    "else:\n",
    "    print(f\"No detections found in {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98135eb0-cae2-4a3e-b5dc-54fdc184575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from: runs/detect/train11/weights/best.pt\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Model weights loaded successfully.\n",
      "Reading test image from: ./blood-dataset/test_images/image-1.png\n",
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 640x640 (no detections), 262.3ms\n",
      "Speed: 3.8ms preprocess, 262.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Test image read successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     exit()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Ensure there are detections in the results\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpred:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Visualize the detection results\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualizing detection results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     results\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Show annotated results to screen\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model\n",
    "model = YOLO()\n",
    "\n",
    "# Load the trained weights\n",
    "weights_path = 'runs/detect/train11/weights/best.pt'\n",
    "print(f\"Loading model weights from: {weights_path}\")\n",
    "model = model.load(weights_path)\n",
    "print(\"Model weights loaded successfully.\")\n",
    "\n",
    "# Perform object detection on test images\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "print(f\"Reading test image from: {image_path}\")\n",
    "try:\n",
    "    results = model(image_path, conf=0.01)\n",
    "    print(\"Test image read successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading test image: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Ensure there are detections in the results\n",
    "if results.pred:\n",
    "    # Visualize the detection results\n",
    "    print(\"Visualizing detection results...\")\n",
    "    results.show()  # Show annotated results to screen\n",
    "    print(\"Detection results visualized.\")\n",
    "    \n",
    "    # Access the detection metrics (optional)\n",
    "    print(\"Accessing detection metrics...\")\n",
    "    for bbox, conf in zip(results.boxes, results.probs):\n",
    "        print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "    print(\"Detection metrics accessed successfully.\")\n",
    "else:\n",
    "    print(f\"No detections found in {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3643f86a-8544-4341-8eac-8e04c464a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-1.png: 256x256 (no detections), 64.2ms\n",
      "Speed: 1.0ms preprocess, 64.2ms inference, 0.6ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Error performing object detection: 'list' object has no attribute 'pred'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model and load weights\n",
    "model = YOLO('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Specify the test image path\n",
    "image_path = './blood-dataset/test_images/image-1.png'\n",
    "\n",
    "try:\n",
    "    # Perform object detection on the test image\n",
    "    results = model(image_path, conf=0.1)\n",
    "\n",
    "    # Ensure there are detections in the results\n",
    "    if results.pred:\n",
    "        # Visualize the detection results\n",
    "        print(\"Visualizing detection results...\")\n",
    "        results.show()  # Show annotated results to screen\n",
    "        print(\"Detection results visualized.\")\n",
    "        \n",
    "        # Access the detection metrics (optional)\n",
    "        print(\"Accessing detection metrics...\")\n",
    "        for bbox, conf in zip(results.boxes, results.probs):\n",
    "            print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "        print(\"Detection metrics accessed successfully.\")\n",
    "    else:\n",
    "        print(f\"No detections found in {image_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error performing object detection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f8e650-9637-4038-93df-b89ea6b28689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-7.png: 256x256 (no detections), 57.6ms\n",
      "Speed: 0.7ms preprocess, 57.6ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Results type: <class 'list'>\n",
      "No detections found in ./blood-dataset/test_images/image-7.png\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model and load weights\n",
    "model = YOLO('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Specify the test image path\n",
    "image_path = './blood-dataset/test_images/image-7.png'\n",
    "\n",
    "try:\n",
    "    # Perform object detection on the test image\n",
    "    results = model(image_path, conf=0.005)\n",
    "    \n",
    "    print(f\"Results type: {type(results)}\")  # Print the type of results returned\n",
    "    \n",
    "    # Ensure there are detections in the results\n",
    "    if isinstance(results, list):\n",
    "        results = results[0]  # Assuming the first element contains the detection results\n",
    "    if hasattr(results, 'pred'):\n",
    "        # Visualize the detection results\n",
    "        print(\"Visualizing detection results...\")\n",
    "        results.show()  # Show annotated results to screen\n",
    "        print(\"Detection results visualized.\")\n",
    "        \n",
    "        # Access the detection metrics (optional)\n",
    "        print(\"Accessing detection metrics...\")\n",
    "        for bbox, conf in zip(results.boxes, results.probs):\n",
    "            print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "        print(\"Detection metrics accessed successfully.\")\n",
    "    else:\n",
    "        print(f\"No detections found in {image_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error performing object detection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090b65de-bdfa-4ffe-bbc8-1e153d1a90b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-17.png: 256x256 31 wbcs, 2 rbcs, 50.4ms\n",
      "Speed: 0.7ms preprocess, 50.4ms inference, 14.2ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Results type: <class 'list'>\n",
      "Number of results: 1\n",
      "Result 1: ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'wbc', 1: 'rbc'}\n",
      "obb: None\n",
      "orig_img: array([[[142, 114, 179],\n",
      "        [146, 121, 177],\n",
      "        [149, 127, 178],\n",
      "        ...,\n",
      "        [150, 124, 183],\n",
      "        [152, 130, 183],\n",
      "        [159, 138, 185]],\n",
      "\n",
      "       [[144, 118, 180],\n",
      "        [146, 124, 177],\n",
      "        [152, 134, 180],\n",
      "        ...,\n",
      "        [152, 127, 183],\n",
      "        [154, 133, 184],\n",
      "        [159, 139, 185]],\n",
      "\n",
      "       [[144, 120, 178],\n",
      "        [147, 131, 180],\n",
      "        [153, 143, 183],\n",
      "        ...,\n",
      "        [150, 127, 180],\n",
      "        [152, 131, 181],\n",
      "        [156, 137, 182]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[133, 104, 177],\n",
      "        [134, 105, 178],\n",
      "        [136, 108, 178],\n",
      "        ...,\n",
      "        [195, 219, 177],\n",
      "        [194, 219, 182],\n",
      "        [193, 217, 182]],\n",
      "\n",
      "       [[134, 105, 177],\n",
      "        [137, 106, 181],\n",
      "        [138, 108, 180],\n",
      "        ...,\n",
      "        [196, 221, 177],\n",
      "        [195, 221, 180],\n",
      "        [192, 218, 179]],\n",
      "\n",
      "       [[135, 106, 177],\n",
      "        [139, 108, 183],\n",
      "        [138, 108, 181],\n",
      "        ...,\n",
      "        [197, 223, 176],\n",
      "        [195, 221, 179],\n",
      "        [193, 219, 179]]], dtype=uint8)\n",
      "orig_shape: (256, 256)\n",
      "path: '/home/max/python_pg/tf_od/blood-dataset/test_images/image-17.png'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 0.7293224334716797, 'inference': 50.388336181640625, 'postprocess': 14.240503311157227}\n",
      "No 'pred' attribute found in results.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model and load weights\n",
    "model = YOLO('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Specify the test image path\n",
    "image_path = './blood-dataset/test_images/image-17.png'\n",
    "\n",
    "try:\n",
    "    # Perform object detection on the test image\n",
    "    results = model(image_path, conf=0.001)\n",
    "    \n",
    "    print(f\"Results type: {type(results)}\")  # Print the type of results returned\n",
    "    print(f\"Number of results: {len(results)}\")  # Print the number of items in results list\n",
    "    \n",
    "    # Visualize the raw results for debugging\n",
    "    for idx, result in enumerate(results):\n",
    "        print(f\"Result {idx + 1}: {result}\")\n",
    "    \n",
    "    # Ensure there are detections in the results\n",
    "    if isinstance(results, list):\n",
    "        if len(results) > 0:\n",
    "            # Assuming the first element contains the detection results\n",
    "            results = results[0]\n",
    "            if hasattr(results, 'pred'):\n",
    "                # Visualize the detection results\n",
    "                print(\"Visualizing detection results...\")\n",
    "                results.show()  # Show annotated results to screen\n",
    "                print(\"Detection results visualized.\")\n",
    "                \n",
    "                # Access the detection metrics (optional)\n",
    "                print(\"Accessing detection metrics...\")\n",
    "                for bbox, conf in zip(results.boxes, results.probs):\n",
    "                    print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "                print(\"Detection metrics accessed successfully.\")\n",
    "            else:\n",
    "                print(f\"No 'pred' attribute found in results.\")\n",
    "        else:\n",
    "            print(f\"No detections found in {image_path}\")\n",
    "    else:\n",
    "        print(f\"Results is not a list.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error performing object detection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "664d6ef3-959c-456e-a209-f3d52132187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/image-4.png: 256x256 29 wbcs, 3 rbcs, 50.0ms\n",
      "Speed: 0.8ms preprocess, 50.0ms inference, 0.8ms postprocess per image at shape (1, 3, 256, 256)\n",
      "Results type: <class 'list'>\n",
      "Number of results: 1\n",
      "Processing Result 1:\n",
      "Visualizing detection results...\n",
      "Detection results visualized.\n",
      "Accessing detection metrics...\n",
      "No bounding boxes or probabilities found.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model and load weights\n",
    "model = YOLO('runs/detect/train11/weights/best.pt')\n",
    "\n",
    "# Specify the test image path\n",
    "image_path = './blood-dataset/test_images/image-4.png'\n",
    "\n",
    "try:\n",
    "    # Perform object detection on the test image\n",
    "    results = model(image_path, conf=0.002)\n",
    "    \n",
    "    print(f\"Results type: {type(results)}\")  # Print the type of results returned\n",
    "    print(f\"Number of results: {len(results)}\")  # Print the number of items in results list\n",
    "    \n",
    "    # Iterate through each Results object\n",
    "    for idx, result in enumerate(results):\n",
    "        print(f\"Processing Result {idx + 1}:\")\n",
    "        \n",
    "        # Visualize the detection results\n",
    "        print(\"Visualizing detection results...\")\n",
    "        result.show()  # Show annotated results to screen\n",
    "        print(\"Detection results visualized.\")\n",
    "        \n",
    "        # Access the detection metrics (optional)\n",
    "        print(\"Accessing detection metrics...\")\n",
    "        if result.boxes is not None and result.probs is not None:\n",
    "            for bbox, conf in zip(result.boxes, result.probs):\n",
    "                print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "            print(\"Detection metrics accessed successfully.\")\n",
    "        else:\n",
    "            print(\"No bounding boxes or probabilities found.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error performing object detection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae8b0e55-b585-4f5e-a6d7-95683fc4d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/max/python_pg/tf_od/blood-dataset/test_images/2.jpg: 192x256 73 rbcs, 74.6ms\n",
      "Speed: 1.6ms preprocess, 74.6ms inference, 0.9ms postprocess per image at shape (1, 3, 192, 256)\n",
      "Results type: <class 'list'>\n",
      "Number of results: 1\n",
      "Processing Result 1:\n",
      "Visualizing detection results...\n",
      "Detection results visualized.\n",
      "Accessing detection metrics...\n",
      "No bounding boxes or probabilities found.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Instantiate YOLO model and load weights\n",
    "model = YOLO('/home/max/python_pg/tf_od/runs/detect/train14/weights/best.pt')\n",
    "\n",
    "# Specify the test image path\n",
    "image_path = './blood-dataset/test_images/2.jpg'\n",
    "\n",
    "try:\n",
    "    # Perform object detection on the test image\n",
    "    results = model(image_path, conf=0.4)\n",
    "    \n",
    "    print(f\"Results type: {type(results)}\")  # Print the type of results returned\n",
    "    print(f\"Number of results: {len(results)}\")  # Print the number of items in results list\n",
    "    \n",
    "    # Iterate through each Results object\n",
    "    for idx, result in enumerate(results):\n",
    "        print(f\"Processing Result {idx + 1}:\")\n",
    "        \n",
    "        # Visualize the detection results\n",
    "        print(\"Visualizing detection results...\")\n",
    "        result.show()  # Show annotated results to screen\n",
    "        print(\"Detection results visualized.\")\n",
    "        \n",
    "        # Access the detection metrics (optional)\n",
    "        print(\"Accessing detection metrics...\")\n",
    "        if result.boxes is not None and result.probs is not None:\n",
    "            for bbox, conf in zip(result.boxes, result.probs):\n",
    "                print(f\"Bounding Box: {bbox}, Confidence: {conf}\")\n",
    "            print(\"Detection metrics accessed successfully.\")\n",
    "        else:\n",
    "            print(\"No bounding boxes or probabilities found.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error performing object detection: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657a23b-0b1c-4b9b-869c-0a9d7e825e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
